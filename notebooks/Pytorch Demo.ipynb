{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from nlpy.torch_models.simple_attention_nn import (\n",
    "    build_vocab,\n",
    "    TextDataset,\n",
    "    AttentionNetwork,\n",
    "    train_epoch,\n",
    "    evaluation)\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/yelp.csv\")\n",
    "train_df, test_val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "test_df, val_df = train_test_split(test_val_df,test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"batch_size\": 128,\n",
    "    \"conv_channels\": 24,\n",
    "    \"conv_kernel_size\": 4,\n",
    "    \"conv_stride\": 2,\n",
    "    \"conv_padding\": 'valid',\n",
    "    \"conv_dilation\": 1,\n",
    "    \"embedding_dim\": 24,\n",
    "    \"dropout_rate\": 0.25,\n",
    "    \"output_size\": 1,\n",
    "    \"learning_rate\": 0.005,\n",
    "    \"max_num_words\": 2000,\n",
    "    \"max_sequence_length\": 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "vocab = build_vocab(\n",
    "    train_df[\"text\"],\n",
    "    tokenizer,\n",
    "    max_tokens=hparams[\"max_num_words\"],\n",
    "    oov_token=\"<OOV>\",\n",
    "    pad_token = \"<PAD>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(\n",
    "    train_df[\"text\"].tolist(),\n",
    "    train_df[\"stars\"].tolist(),\n",
    "    max_sequence_length=hparams[\"max_sequence_length\"],\n",
    "    tokenizer=tokenizer,\n",
    "    vocab=vocab)\n",
    "\n",
    "val_dataset = TextDataset(\n",
    "    val_df[\"text\"].tolist(),\n",
    "    val_df[\"stars\"].tolist(),\n",
    "    max_sequence_length=hparams[\"max_sequence_length\"],\n",
    "    tokenizer=tokenizer,\n",
    "    vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,hparams[\"batch_size\"],shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset,hparams[\"batch_size\"],shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SimpleTextCNN(nn.Module):\n",
    "#     def __init__(self, num_embeddings=10000, embedding_dim=64, padding_idx=1,\n",
    "#     conv_out_channels=12, conv_kernel_size=5):\n",
    "#         super(SimpleTextCNN, self).__init__()\n",
    "#         self.embedding = nn.Embedding(\n",
    "#             num_embeddings=num_embeddings,\n",
    "#             embedding_dim=embedding_dim,\n",
    "#             padding_idx=padding_idx)\n",
    "#         self.conv1d = nn.Conv1d(\n",
    "#             in_channels=embedding_dim,\n",
    "#             out_channels=conv_out_channels,\n",
    "#             kernel_size=conv_kernel_size)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttentionNetwork(\n",
    "    sequence_length=hparams[\"max_sequence_length\"],\n",
    "    num_embeddings=len(vocab),\n",
    "    embedding_dim=hparams[\"embedding_dim\"],\n",
    "    padding_idx=1,\n",
    "    att_num_heads=4,\n",
    "    dropout=0.25,\n",
    "    output_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hparams[\"learning_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce MX250\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 0\n",
      "Training mean loss:  3.319  \n",
      "Training time elapsed:   7.47  \n",
      "Val mean loss:  1.288  \n",
      "Val time elapsed:   0.39  \n",
      "Training Epoch: 1\n",
      "Training mean loss:  1.254  \n",
      "Training time elapsed:   5.52  \n",
      "Val mean loss:  1.111  \n",
      "Val time elapsed:   0.37  \n",
      "Training Epoch: 2\n",
      "Training mean loss:  1.069  \n",
      "Training time elapsed:   5.53  \n",
      "Val mean loss:  1.139  \n",
      "Val time elapsed:   0.37  \n",
      "Training Epoch: 3\n",
      "Training mean loss:  0.952  \n",
      "Training time elapsed:   5.49  \n",
      "Val mean loss:  0.924  \n",
      "Val time elapsed:   0.37  \n",
      "Training Epoch: 4\n",
      "Training mean loss:  0.840  \n",
      "Training time elapsed:   5.48  \n",
      "Val mean loss:  0.894  \n",
      "Val time elapsed:   0.38  \n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "for epoch in range(5):\n",
    "    mean_train_loss, time_elapsed = train_epoch(\n",
    "        model, train_dataloader, loss_fn, optimizer, device)\n",
    "    print(f\"Training Epoch: {epoch}\")\n",
    "    print(f\"Training mean loss: {mean_train_loss:^8.3f}\")\n",
    "    print(f\"Training time elapsed: {time_elapsed:^8.2f}\")\n",
    "    eval_loss, time_elapsed = evaluation(model, val_dataloader, loss_fn, device) \n",
    "    print(f\"Val mean loss: {eval_loss:^8.3f}\")\n",
    "    print(f\"Val time elapsed: {time_elapsed:^8.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.2+cu113'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bc7f50390e42f6c1331f86e9f26dea63ec7b34656187ee4894a92f7c1595689f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
