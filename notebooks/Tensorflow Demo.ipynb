{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\grego\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import time\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nlpy.tf_models.preprocess import prep_text, dataset_callable\n",
    "from nlpy.tf_models.simple_text_cnn import SimpleTextCNN, train_step, test_step\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/yelp.csv\")\n",
    "train_df, test_val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "test_df, val_df = train_test_split(test_val_df,test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date  ... useful  funny\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  ...      5      0\n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  ...      0      0\n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  ...      1      0\n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  ...      2      0\n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  ...      0      0\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"batch_size\": 128,\n",
    "    \"conv_channels\": 24,\n",
    "    \"conv_kernel_size\": 4,\n",
    "    \"conv_stride\": 2,\n",
    "    \"conv_padding\": 'valid',\n",
    "    \"conv_dilation\": 1,\n",
    "    \"embedding_dim\": 100,\n",
    "    \"dropout_rate\": 0.25,\n",
    "    \"output_size\": 1,\n",
    "    \"learning_rate\": 0.005,\n",
    "    \"max_num_words\": 10000,\n",
    "    \"max_sequence_length\": 250}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=hparams[\"max_num_words\"])\n",
    "tokenizer.fit_on_texts(train_df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset_callable(\n",
    "    train_df[\"text\"], train_df[\"stars\"], tokenizer,\n",
    "    hparams[\"max_sequence_length\"], hparams[\"batch_size\"])\n",
    "\n",
    "test_dataset = dataset_callable(\n",
    "    test_df[\"text\"], test_df[\"stars\"], tokenizer,\n",
    "    hparams[\"max_sequence_length\"], hparams[\"batch_size\"])\n",
    "\n",
    "val_dataset = dataset_callable(\n",
    "    val_df[\"text\"], val_df[\"stars\"], tokenizer,\n",
    "    hparams[\"max_sequence_length\"], hparams[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = SimpleTextCNN(\n",
    "  sequence_length=hparams[\"max_sequence_length\"],\n",
    "  embedding_input_dim=hparams[\"max_num_words\"],\n",
    "  embedding_dim=hparams[\"embedding_dim\"],\n",
    "  conv_channels=hparams[\"conv_channels\"],\n",
    "  conv_kernel_size=hparams[\"conv_kernel_size\"],\n",
    "  conv_stride=hparams[\"conv_stride\"],\n",
    "  conv_padding=hparams[\"conv_padding\"],\n",
    "  conv_dilation=hparams[\"conv_dilation\"],\n",
    "  dropout_rate=hparams[\"dropout_rate\"],\n",
    "  output_size=hparams[\"output_size\"])\n",
    "\n",
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_rmse = tf.keras.metrics.RootMeanSquaredError(name='train_rmse')\n",
    "\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "val_rmse = tf.keras.metrics.RootMeanSquaredError(name='val_rmse')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_rmse = tf.keras.metrics.RootMeanSquaredError(name='test_rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loss, train_dataset, train_rmse,\n",
    "    val_loss, val_dataset, val_rmse, epochs=5):\n",
    "    print(\"Start training...\\n\")\n",
    "    print(f\"{'Epoch':^7} | {'Train Loss':^12} | {'Train RMSE':^9} \" +\n",
    "          f\"| {'Val Loss':^10} | {'Val RMSE':^9} | {'Elapsed':^9}\")\n",
    "    print(\"-\"*60)\n",
    "    best_val_loss = None\n",
    "    for epoch in range(epochs):\n",
    "        t0_epoch = time.time()\n",
    "        train_loss.reset_state()\n",
    "        train_rmse.reset_state()\n",
    "        val_loss.reset_state()\n",
    "        val_rmse.reset_state()\n",
    "\n",
    "        for train_features, train_targets in train_dataset():\n",
    "            train_step(model, train_features, train_targets,\n",
    "            loss_object, optimizer, train_loss, train_rmse)\n",
    "\n",
    "        for val_features, val_targets in val_dataset():\n",
    "            test_step(model, val_features, val_targets,\n",
    "            loss_object, val_loss, val_rmse)\n",
    "\n",
    "        time_elapsed = time.time() - t0_epoch\n",
    "        print(f\"{epoch+1:^7} | {train_loss.result():^12.6f} | {train_rmse.result():^9.2f}\" +\n",
    "              f\" | {val_loss.result():^10.6f}\" +\n",
    "              f\" | {val_rmse.result():^9.2f} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "        if best_val_loss is not None and val_loss.result() > best_val_loss:\n",
    "            print(\"Stopping early: Val loss increased\")\n",
    "            break\n",
    "        else:\n",
    "            best_val_loss = val_loss.result()\n",
    "    print(f\"Training completed! Final validation RMSE: {val_rmse.result():.2f}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Train Loss  | Train RMSE |  Val Loss  | Val RMSE  |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   1    |   2.078290   |   1.44    |  1.455616  |   1.21    |   2.89   \n",
      "   2    |   1.873044   |   1.37    |  1.344856  |   1.16    |   2.41   \n",
      "   3    |   1.733359   |   1.32    |  1.246642  |   1.12    |   2.38   \n",
      "   4    |   1.535503   |   1.24    |  1.094809  |   1.04    |   2.34   \n",
      "   5    |   1.353235   |   1.16    |  0.987829  |   0.99    |   2.36   \n",
      "   6    |   1.197986   |   1.10    |  0.955442  |   0.98    |   2.34   \n",
      "   7    |   1.117679   |   1.06    |  0.937782  |   0.97    |   2.35   \n",
      "   8    |   1.042802   |   1.02    |  0.936548  |   0.97    |   2.39   \n",
      "   9    |   0.962515   |   0.98    |  0.931646  |   0.96    |   2.41   \n",
      "  10    |   0.918046   |   0.96    |  0.924252  |   0.96    |   2.42   \n",
      "  11    |   0.877753   |   0.94    |  0.914719  |   0.95    |   2.44   \n",
      "  12    |   0.851820   |   0.92    |  0.930068  |   0.96    |   2.51   \n",
      "Stopping early: Val loss increased\n",
      "Training completed! Final validation RMSE: 0.96.\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loss, train_dataset, train_rmse, val_loss, val_dataset, val_rmse, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bc7f50390e42f6c1331f86e9f26dea63ec7b34656187ee4894a92f7c1595689f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
